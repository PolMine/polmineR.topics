---
title: "Create LDA Topic Model"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Create LDA Topic Model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
params:
  package: "polmineR"
  corpus: "GERMAPARLMINI"
  k: 250
  language: "de"
---

```{sh command_line_use, eval = FALSE}
Rscript -e 'rmarkdown::render(input = "01_CWBToLDA.Rmd", output_format = "html_document", output_file = "lda_reports/cwb_to_lda_germaparlmini.html", params = list(package = "GermaParl", corpus = "GERMAPARLMINI", k = 250, language = "de"))'
```


````{r}
package_to_use <- params$package
corpus <- toupper(params$corpus)
k <- as.integer(params$k)
language <- params$language
```

```{r}
message(sprintf("Package to use: %s", package_to_use))
message(sprintf("Corpus to use: %s", corpus))
message(sprintf("Number of topics (k): %s", k))

get_corpus_build_date <- function(package, corpus) {
  firstline <- readLines(paste0(system.file(package = package, "extdata", "cwb", "indexed_corpora", tolower(corpus)), "/info.md"))[1]
  date <- gsub(".*build (.*?)\\)", "\\1", firstline)
  date <- as.Date(date)
  return(date)
}

corpus_build_date <- get_corpus_build_date(package = package_to_use, corpus = corpus)
if (!inherits(corpus_build_date, "Date")) corpus_build_date <- "YYYY-MM-DD"

lda_filename <- sprintf("lda_%s_%s_%s_%s.rds", corpus, corpus_build_date, k, Sys.Date())


message("LDA model will be written to: ", lda_filename)
```


# Load libraries

```{r}
library(polmineR)
library(data.table)
library(pbapply)
library(topicmodels)
```

# Activate Corpus Package

```{r}
use(package_to_use)
```

# Preventing Encoding Issues

```{r}

if (.Platform$OS.type == "unix" && polmineR::registry_get_encoding(corpus) == "latin1") {
  
  cwbtools::corpus_recode(corpus = corpus, 
                          registry_dir = system.file(package = package, "extdata", "cwb", "registry"),
                          data_dir = system.file(package = package, "extdata", 
                                                 "cwb", "indexed_corpora", tolower(corpus)),
                          to = "utf8")
  
  RcppCWB::cqp_reset_registry()
  use(package)

}

```

# Get going

```{r}
speeches <- as.speeches(.Object = corpus, sAttributeDates = "date", sAttributeNames = "name")
count_bundle <- count(speeches, pAttribute = "word", verbose = TRUE)
rm(speeches)
```

```{r}
message("... create DocumentTermMatrix")

# Create DocumentTermMatrix
dtm <- as.DocumentTermMatrix(count_bundle, pAttribute = "word", col = "count")
```

```{r}
# minimum document length 100 words
docs_to_drop_length <- which(slam::row_sums(dtm) < 100) # less than 100
if (length(docs_to_drop_length) > 0) dtm <- dtm[-docs_to_drop_length,]

# remove noisy words
noise_to_drop <- noise(colnames(dtm), specialChars = NULL, stopwordsLanguage = language)
noise_to_drop[["stopwords"]] <- c(
  noise_to_drop[["stopwords"]],
  paste(
    toupper(substr(noise_to_drop[["stopwords"]], 1, 1)),
    substr(noise_to_drop[["stopwords"]], 2, nchar(noise_to_drop[["stopwords"]])),
    sep = ""
  )
)

dtm <- dtm[,-which(colnames(dtm) %in% unique(unname(unlist(noise_to_drop))))]

# remove rare words
terms_to_drop_rare <- which(slam::col_sums(dtm) <= 10)
if (length(terms_to_drop_rare) > 0) dtm <- dtm[,-terms_to_drop_rare]

# remove documents that are empty now
empty_docs <- which(slam::row_sums(dtm) == 0)
if (length(empty_docs) > 0) dtm <- dtm[-empty_docs,]
```

```{r}
lda <- LDA(
  dtm, k = k, method = "Gibbs",
  control = list(burnin = 1000, iter = 3L, keep = 50, verbose = TRUE)
)
```

```{r}
saveRDS(object = lda, file = lda_filename)
```
