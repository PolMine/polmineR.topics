% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Topicanalysis.R
\docType{data}
\name{Topicanalysis}
\alias{Topicanalysis}
\title{Topicanalysis Class.}
\format{An object of class \code{R6ClassGenerator} of length 25.}
\usage{
Topicanalysis
}
\description{
Analyse topicmodels.
}
\section{Fields}{

\describe{
\item{\code{topicmodel}}{A topicmodel of class \code{TopicModel}, generated from
package \code{topicmodels}.}

\item{\code{posterior}}{Slot to store posterior, not used at this point.}

\item{\code{terms}}{The \code{matrix} with the terms of a topicmodel. Keeping the
terms may speed up subsequent operations.}

\item{\code{topics}}{The \code{matrix} with the topics present in documents. Keeping
this matrix may speed up subsequent operations.}

\item{\code{bundle}}{A \code{partition_bundle}, required to use method \code{read}
to access full text.}

\item{\code{labels}}{A \code{character} vector, labels for the topics.}

\item{\code{name}}{A name for the \code{Topicanalysis} object. Useful if combining
several objects into a bundle.}

\item{\code{categories}}{A \code{character} vector with categories.}

\item{\code{grouping}}{Not used at this stage.}

\item{\code{exclude}}{Topics to exclude from further analysis.}

\item{\code{type}}{Corpus type, necessary for applying correct template for fulltext output.}
}}

\section{Arguments}{

\describe{
  \item{new}{New value for a label or a category.}
  \item{n}{Number of a topic.}
  \item{n_words}{An \code{integer}, the number of words to be displayed in a wordcloud.}
  \item{x}{Number or name of a topics.}
  \item{y}{Number or name of a topic cooccurring with x.}
  \item{k}{Number of top topics of a document to consider.}
  \item{exclude}{A \code{logical} value, whether to to exclude topics
  earmarked in logical vector in field exclude.}
  \item{aggregation}{Level of aggregation of \code{as.zoo} method.}
  \item{...}{Further parameters passed to worker function (such as
  \code{wordcloud::wordcloud} when calling \code{$wordcloud()}, for
  instance).}
  \item{regex}{A regular expression that will limit the evaluation to those documents only
  that are matched by the regular expression.}
}
}

\section{Methods}{

\describe{
  \item{\code{$initialize(topicmodel)}}{Instantiate new \code{Topicanalysis}
  object. Upon initialization, labels will be the plain numbers of the
  topics, all exclude values are \code{FALSE}.}
  \item{\code{$cooccurrences(k = 3, regex = NULL, docs = NULL, renumber = NULL,
  progress = TRUE, exclude = TRUE)}}{Get cooccurrences of topics. Arguments are
  documented with the S4 cooccurrences-method for TopicModel-objects.}
  \item{\code{$relabel(n, new)}}{Relabel topic \code{n}, assigning new label
  \code{new}.}
  \item{\code{$add_category(new)}}{Add \code{new}, a \code{character} vector
  as a new category to the \code{character} vector in the field
  \code{category}.}
  \item{\code{$ignorance(n, new)}}{Exclude topic \code{n} (i.e. add to ignore).}
  \item{\code{$wordcloud(n, n = 50, ...)}}{Generate wordcloud for topic
  \code{n}, with \code{n_words} words. Further arguments can be passed into
  \code{wordcloud::wordcloud} usint the three dots.}
  \item{\code{$docs(x, y = NULL, n = 3L, s_attributes = NULL)}}{Get documents
  where topic \code{x} occurrs among the top \code{n} topics. If \code{y} is 
  provided, documents are returned where \code{x} and \code{y} are among the
  \code{n} top topics. If \code{x} or \code{y} are provided as a \code{character}
  vector, the method will look up this label in the \code{labels} field.}
  \item{\code{$read(x, n = 3, no_token = 100)}}{Read document \code{x},
  highlighting the number of topics specified by \code{n}, indicated by
  \code{no_token}.}
  \item{\code{$as.zoo(x = NULL, y = NULL, k = 3, exclude = TRUE, aggregation
  = c(NULL, "month", "quarter", "year"))}}{Generate \code{zoo} object from
  topicmodel.}
  \item{\code{$compare(x, ...)}}{Compare the similarity of two topicmodels.}
  \item{\code{$find_topics(x, n = 100, word2vec = NULL)}}{Find a topic.}
}
}

\examples{
data(BE_lda)
data(BE_labels)
data(BE_exclude)

BE <- Topicanalysis$new(topicmodel = BE_lda)
BE$labels <- BE_labels
BE$exclude <- BE_exclude
BE$exclude <- grepl("^\\\\((split|)\\\\)$", BE$labels)
BE$name <- "Berlin"
BE$type <- "plpr_partition"

z <- BE$as.zoo(x = "Flucht, Asyl, vorläufiger Schutz", aggregation = "year")
plot(z)

y <- BE$as.zoo(
  x = grep("Asyl", BE_labels),
  y = grep("Europ", BE_labels),
  aggregation = "year"
)
plot(y)

BE$exclude <- grepl("^\\\\(.*?\\\\)$", BE$labels)
dt <- BE$cooccurrences(k = 3L, exclude = TRUE)
dt_min <- dt[chisquare >= 10.83]


if (requireNamespace("igraph")){
g <- igraph::graph_from_data_frame(
  d = data.frame(
    from = dt_min[["a_label"]],
    to = dt_min[["b_label"]],
    n = dt_min[["count_coi"]],
    stringsAsFactors = FALSE
  ),
  directed = TRUE
)
g <- igraph::as.undirected(g, mode = "collapse")
if (interactive()){
  igraph::plot.igraph(
    g, shape = "square", vertex.color = "steelblue",
    label = igraph::V(g)$name, label.family = 11, label.cex = 0.5
  )
}
}

topic_flucht <- 125L
topic_integration <- 241
BE$docs(x = "Flucht, Asyl, vorläufiger Schutz")
BE$docs(x = grep("Flucht", BE$labels))
BE$docs(x = 125L)
docs <- BE$docs(x = 125L, y = 241L)

\dontrun{
li <- lapply(
  docs, 
  function(doc){
    polmineR::as.speeches(
      polmineR::partition(
        "BE",
        who = gsub("^(.*?)_.*$", "\\\\1", doc),
        date = gsub("^.*(\\\\d{4}-\\\\d{2}-\\\\d{2})_\\\\d+$", "\\\\1", doc)
      ),
      s_attribute_name = "who"
    )[[as.integer(gsub("^.*?_(\\\\d+)$", "\\\\1", doc))]]
})
BE$bundle <- as.partition_bundle(li)

read(BE$topicmodel, BE$bundle[[1]], n = 3L, no_token = 250)
read(BE$topicmodel, BE$bundle[[2]], n = 3L, no_token = 250)
read(BE$topicmodel, BE$bundle[[3]], n = 3L, no_token = 250)
for (doc in docs){
  print(doc)
  p <- BE$bundle[[doc]]
  read(BE$topicmodel, p, n = 3L, no_token = 250)
  readline(prompt = "Hit any key to continue.")
}
}

#############################

data(SL_lda)
data(SL_labels)
data(SL_exclude)

SL <- Topicanalysis$new(topicmodel = SL_lda)
SL$labels <- SL_labels
SL$exclude <- SL_exclude
SL$exclude <- grepl("^\\\\((split|)\\\\)$", SL$labels)
SL$name <- "Hamburg"

cp_1 <- BE$compare(SL, BE)
cp_2 <- BE$compare(SL, BE)

}
\keyword{datasets}
